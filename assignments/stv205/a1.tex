\documentclass[12pt]{article}
\usepackage{amsmath,amssymb,bookmark,graphicx,parskip,textcomp,custom}
\usepackage[margin=.8in]{geometry}
\allowdisplaybreaks
\hypersetup{colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\begin{document}

\title{STV 205 --- Assignment 1}
\author{Kevin Carruthers (20463098)}
\date{\vspace{-2ex}Winter 2017}
\maketitle\HRule

\section*{}
In ``Automation Makes Us Dumb: Human intelligence is withering as computers do more, but there is a solution'', Nicholas Carr argues that human intelligence is linked inversely with the quality of our tools and automation; that is, as we improve these utilities we lose the ability for human operators using these tools to use their own natural abilities to solve the problems now being solved by automation. He argues this can cause many problems down the line as human operators become ``de-skilled'' and effectively nothing more than simple button pushers. Furthermore, he argues that there is a solution: that changing our methods for implementing intelligent tools can allow us to build automation that works with their operators rather than against them, allowing the operators to continue refining their skills in spite of their usage of these tools. He calls this ``adaptive automation'' and describes it as a form of automation which varies in capability as it detects the interest and attention of the operator to be waxing or waning.

One of Carr's most poignant points is that humans improve their skills by using them (ie. their skills). Automation, then, prevents us from using our skills and thereby renders them less and less effective as our dependency on this technology increases. By taking this to the absolute conclusion, Carr imagines that all of our skills will become completely ineffectual since we have had no need to practice them. He argues, then, that this can cause devasting effects; if an airline pilot's skills in landing a plane unassisted from the airplane's automation have languished to nothingness and the automation has issues, this can cause fatal plane crashes.

Carr's solution to this, human-centered automation, is in opposition to how he describes the current state of automation development -- that is technology-centered automation. In this technology focused methodology, Carr argues automation is concerned more with automating the things which computers are better at rather than automating the things which humans would benefit most from having automated. By moving from the former (technology-centered) to the latter (human-centered), Carr argues that automation will be to a much greater benefit to humanity and will ``up-skill'' us rather than ``de-skilling'' us.

Technology-centered automation, then, can be considered very similar to McCulloch's original ideas of mechanization as an approach to classical AI. In the mechanistic field, technology is improved for its own sake, gradually performing a great number of tasks in ever increasing quality. This is, as Carr described, how technology works today; technology evolves as we automate all the tasks which it can currently automate, then use what we learned in doing that to automate ever more complicated tasks. As we continue this process ad nauseum, automation becomes very good at performing the tasks which are easiest for computers rather than those that are simplest for humans. There is, of course, no guarantee as to whether these are or are not the same thing.

Conversely, human-centered automation can be considered as a return to the early ideas of cybernetics first popularized by Weiner. This ideas focused more on the idea of humans being in control of the technology or automation and using it very explicitly for more specific purposes rather than as a replacement for their own thought processes or learned skills. In this way, the technology would be more of an augmentation to a human operator than a replacement, Carr and Weiner both argued. These early forms of cybernetics emphasized the value of allowing the human thought process to continue as it had and to automate away only the busy work as an aid -- but not a crutch -- for human innovation. In the same way, Carr argues that human-centered automation would lead to creating automation that is used in ways that do not hinder and ``de-skill'' us.

Carr's idea of ``adaptive automation'' is an interesting one. He argues that the automation system should vary the amount of work it offloads onto the human operator as the operator's interest waxes and wanes. I believe this approach has numerous issues in achieving the goals of human-centered automation. Though it may indeed be closer to the human-centric model of automation than our current automation systems, it could also cause many issues. Not the least of these issues is that Carr's proposed system seems to ignore the fact that the human operator may indeed be bored or annoyed with doing the busy work itself. According to Carr's model, a true ``adaptive'' system would, in that case, assign the operator even more of that busy work as a way of compensating for their distraction. Clearly, this could cause severe problems as well as fostering increased annoyance with attempts to perform the task for which we have used this so-called ``adaptive'' system.

As an operator of an ``adaptive system'', I imagine I would feel as if I had no agency whatsoever. One of the major advantages of a ``non-adaptive system'' is that it can be used selectively depending on the operator's desires -- for example: though arithmetic can be automated, only an operator utterly unconcerned with the quality of his results would not use their own arithmetic skills to verify the result or, indeed, perform a calculation themselves now and again to ensure they keep their skills valid. Instead, it should be up to the author to chose which proportion of the maths he should be willing to do rather than losing his agency by having that choice made for him. Allowing the operator to automate away the portions of their work which they are not interested in or which is grunt work, rather than being a negative, is indeed the opposite -- this allows them an unparalleled amount of agency and frees up their mind to be used on the interesting parts of their work.

As an operator, I feel like an ``adaptive system'' would be a remarkable drain on the quality of the work that I can perform as well as causing a major reduction to my enjoyment and desire to perform said work.

\end{document}
